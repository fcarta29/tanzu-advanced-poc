TODO[fcarta]

# SC02-TC03: Use Pod Security Policies with a Tanzu Kubernetes Cluster(s)

Kubernetes pod security policies (PSPs) are cluster-level resources that control the security of pods. PSPs gives control over the types of pods that can be deployed and the types of accounts that can deploy them. Tanzu Kubernetes Grid Service provisions Tanzu Kubernetes clusters with the PodSecurityPolicy Admission Controller enabled. This means that pod security policy is required to deploy workloads. There are two default pod security policies for Tanzu Kubernetes clusters, which are vmware-system-privileged and vmware-system-restricted. The vmware-system-privileged policy is a permissive policy and equivalent to running a cluster without the PSP admission controller enabled. The vmware-system-restricted policy is a restrictive policy that does not permit privileged access to pod containers, blocks possible escalations to root, and requires use of several security controls. Because non-administrative users cannot create privileged or unprivileged pods at all without the proper PSP and bindings, the DevOps engineer must define bindings to allow or restrict the types of pods users can deploy to a Tanzu Kubernetes cluster. For additional details, reference: 
[Using Pod Security Polices with Tanzu Kubernetes Clusters](https://docs.vmware.com/en/VMware-vSphere/7.0/vmware-vsphere-with-kubernetes/GUID-73352A3E-0C72-446B-A1A5-EB14818605B9.html) and [Kubernetes Pod Security Policies](https://kubernetes.io/docs/concepts/policy/pod-security-policy/)

---

## Test Case Summary

This test case procedure demonstrates using the default pod-security policies when deploying workloads and identifying deployment issues related to psp restrictions. Next, it demonstrates applying a custom psp, clusterrole, and rolebinding for accommodating workloads that have requirements between the spectrum of the two default policy options. Lastly, it demonstrates applying a custom cluster policy for serviceaccounts that namespaces automatically inherit.

---

## Prerequisites

* SC01-TC01,SC01-TC02,SC01-TC04
* DevOps Engineer console and user credentials
* Local clone of [ModernAppsNinja/v7k8s-tc-templates](https://github.com/ModernAppsNinja/v7k8s-tc-templates.git)

---

## Test Procedure

1. Using the **DevOps Engineer** console and credentials, login to the TKC API. Reference the [Configuration Supplement](../supplements/client-configuration.md##-Login-to-a-Tanzu-Kubernetes-Cluster-as-a-vCenter-Single-Sign-On-User) for details on obtaining the CLI tools and command syntax.

2. Create a new namespace named psp-test

    ```sh
    kubectl create ns psp-test
    ```

3. Deploy the following pod specs to the psp-test namespace

    ```sh
    kubectl apply -f sc01/pod-default.yaml -n psp-test
    kubectl apply -f sc01/pod-runasany.yaml -n psp-test
    kubectl apply -f sc01/pod-privileged.yaml -n psp-test
    ```

4. Monitor pods’ status until all pods report `READY=`**`1/1`** and `STATUS=`**`Running`**

    ```sh
    kubectl get pods -w -n psp-test
    ```

5. Deploy the following deployment spec to the psp-test namespace

    ```sh
    kubectl apply -f sc01/pod-deploy.yaml -n psp-test
    ```

6. View the deployment status with the command

    ```sh
    kubectl get deploy pod-deploy -n psp-test
    ```

7. List the deployment’s pods

    ```sh
    kubectl get pods -l app=pod-deploy
    ```

8. Review the events for faults

    ```sh
    kubectl get events -n psp-test --sort-by=.metadata.creationTimestamp |grep pod-deploy|grep Failed 
    ```

9. List the default pod-security policies and settings

    ```sh
    kubectl get psp
    ```

10. Apply a rolebinding to the default psp, vmware-system-restricted, permitting seviceaccounts to instantiate pods in the psp-test namespace

    ```sh
    kubectl apply -f sc01/psp-test-sa-rolebinding-restricted-psp.yaml
    ```

11. List the deployment’s pods

    ```sh
    kubectl get pods -l app=pod-deploy -n psp-test
    ```

12. Review the events for faults

    ```sh
    kubectl get events -n psp-test --sort-by=.metadata.creationTimestamp |grep pod-deploy|grep Failed 
    ```

13. Edit the active deployment spec to disable privileged pod containers

    ```sh
    kubectl edit deploy pod-deploy -n psp-test
    ```

14. Change the container security context value for privileged containers from `true` to **`false`**. Then, press **[esc]**, type **`:wq`** , and press **[return]** to save and exit
    <pre>...<br>spec.template.spec.containers.securityContext.privileged: <b>false</b><br>...</pre>

15. Monitor the pod creation process for up to 60 seconds with the watch option

    ```sh
    kubectl get pods -n psp-test -l app=pod-deploy -w
    ```

16. Review the events for faults

    ```sh
    kubectl get events -n psp-test --sort-by=.metadata.creationTimestamp |grep pod-deploy|grep Failed 
    ```

17. Delete the rolebinding to the default psp, vmware-system-restricted, initially created for permitting serviceaccounts to instantiate pods in the namespace.

    ```sh
    kubectl delete -f sc01/psp-test-sa-rolebinding-restricted-psp.yaml -n psp-test
    ```

18. Instead of editing a default psp, create a custom psp that prevents privileged pod containers from running but permits pod containers to run as any user. Using a text-editor open and review the *sc01/psp-test-psp-cr-rb.yaml*.
19. Apply the new psp, clusterrole, and rolebinding

    ```sh
    kubectl apply -f sc01/psp-test-psp-cr-rb.yaml -n psp-test
    ```

20. Delete the faulted pod, forcing the deployment to create a replacement

    ```sh
    kubectl delete pods -n psp-test -l app=pod-deploy
    ```

    Monitor the new pods with the watch option for 30 secs

    ```sh
    kubectl get pods -n psp-test -l app=pod-deploy -w
    ```

21. Open a shell to the pod-deploy deployment’s pod and identify the user account running the pod container 

    ```sh
    kubectl exec -it pod-deploy-6dfc4f95bc-snxkd sh -n psp-test
    ```

    Then, at the prompt enter id, record the output and close the shell

    ```sh
    id
    ```

22. Verify the privileged pod container restriction is in effect by deleting the deployment then recreating it

    ```sh
    kubectl delete deploy pod-deploy -n psp-test
    kubectl apply -f sc01/pod-deploy.yaml -n psp-test
    ```

23. Monitor the new pod’s with the watch option for 30 secs

    ```sh
    kubectl get pods -n psp-test -l app=pod-deploy -w
    ```

24. Review the events to confirm the fault

    ```sh
    kubectl get events -n psp-test --sort-by=.metadata.creationTimestamp |grep pod-deploy|grep Failed 
    ```

25. Clean up by deleting the psp-test namespace

    ```sh
    kubectl delete ns psp-test
    ```

26. With exception to specific test cases that may require enabling support for privileged containers, apply the following spec as a default cluster binding, allowing system service accounts to deploy nonprivileged containers and run containers as any user.

    ```sh
    kubectl apply -f sc01/psp-test-psp-cr-crb.yaml
    ```

---

## Test Data

* Container image: `nginx:latest`

---

## Expected Results

Step | Result |
--- | --- |
4 | <pre>NAME             READY   STATUS    <br>pod-default      1/1     Running   <br>pod-privileged   1/1     Running   <br>pod-runasroot    1/1     Running   </pre> |
6 | <pre>NAME         READY   UP-TO-DATE   AVAILABLE   <br>pod-deploy   0/1     0            0           </pre> |
7 | <pre>NAME         READY   UP-TO-DATE   AVAILABLE   <br>pod-deploy   0/1     0            0           </pre> |
8 | <pre>Warning FailedCreate replicaset/pod-deploy-xxxxxxxx   Error creating: pods "pod-deploy-xxxxxxxx -" is forbidden: unable to validate against any pod security policy: []</pre> |
11 | <pre>No resources found in psp-test namespace.</pre> |
12 | <pre>Warning FailedCreate replicaset/pod-deploy-xxxxxxxx   Error creating: pods "pod-deploy-xxxxxxxx -" is forbidden: unable to validate against any pod security policy: [spec.containers[0].securityContext.privileged: Invalid value: true: Privileged containers are not allowed]</pre> |
14 | <pre>deployment.apps/pod-deploy edited</pre> |
15 | <pre>NAME                          READY   STATUS                       <br>pod-deploy-xxxxxxxx-xxxxx   0/1     CreateContainerConfigError   </pre> |
16 | <pre>Warning Failed pod/pod-xxxxxxxx-xxxxx Error: container has runAsNonRoot and image will run as root</pre> |
19 | <pre>podsecuritypolicy.policy/custom-psp-nonpriv-runasany created<br>`clusterrole.rbac.authorization.k8s.io/psp:custom-psp-nonpriv-runasany` created<br>`rolebinding.rbac.authorization.k8s.io/psp:custom-psp-nonpriv-runasany-psp-test` created</pre> |
20 | <pre>NAME                          READY   STATUS    <br>pod-deploy-xxxxxxxx-xxxxx      1/1    Running   </pre> |
21 | <pre>uid=0(root) gid=0(root) groups=0(root)</pre> |
24 | <pre>Warning   FailedCreate        replicaset/pod-deploy-xxxxxxxx   Error creating: pods "pod-deploy-xxxxxxxx -" is forbidden: unable to validate against any pod security policy: [spec.containers[0].securityContext.privileged: Invalid value: true: Privileged containers are not allowed]</pre> |

---

## Actual Results

Step | Result |
--- | --- |
4 |  |
6 |  |
7 |  |
8 |  |
11 |  |
12 |  |
14 |  |
15 |  |
16 |  |
19 |  |
20 |  |
21 |  |
24 |  |

---

## Status Pass/Fail

* [  ] Pass
* [  ] Fail

Return to [Test Cases Inventory](../README.md###Test-Cases-Inventory)